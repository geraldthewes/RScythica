\documentclass{article}

\usepackage[toc,page]{appendix}

\begin{document}
\SweaveOpts{concordance=TRUE}

\title{RScythica - A Memory Mapped Vector Oriented Data Set}

\author{Gerald Hewes}

\maketitle

\tableofcontents

\section{Introduction}

RScythica Dataframes, also called S Dataframes, are large scale, read-only, memory-mapped
data sets which are both partioned and
broken into large splits. S Dataframes are created using external utilities.

\subsection{Background}

Scythica was developed to help data scientist analyze large datasets in R. Key features are:

\begin{itemize}
  \item S Datasets consists of multiple binary files that hold data in columns of vectors. The files are   mapped directly into an R process using R 3.1.0 support for custom allocators. The data is pre-processed by external utilities. Since R memory maps the data directly into it's process, access is very fast and much more efficient.
  \item Data is by default partitioned by one of the dataset columns. For example in ad tech it is common to partition data by date.
  \item To handle really large partitions, the partitions can be broken into multiple splits.
Effectivily the key to a vector consists of the partition plus the split index.
\end{itemize}


\section{Simple Example}

Typically you receive data in a large CSV file. Before it can be used in R, the CSV file need to be transformed in a binary Scythica dataset.

\subsection{Creating a Dataset}

The first step is creating the necessary configuration file in YAML format. RScythica comes with a utily function to generate a templated configration

<<>>=
library(yaml)
library(RScythica)
# Use read.table to read 100 rows
sample <- read.table('../tests/extdata/airline.csv',sep=',', header=TRUE, nrows=100)
# Create a templated file that can be edited
makeconfig('example.yaml',sample)
@

Talk about partitions...

Then process the CSV file using the sdscreate executable

<<eval=FALSE>>=
#sdscreate airline.yaml airline.sds airline.csv
@

\subsection{Basic Usage of Datasets}


<<>>=
library(RScythica)

#Open Dataset
ds <- open_sdataset("../tests/extdata/airline.sds")
print(ds)

# Return number of columns in the dataset
ds$ncol()

# Return the column names and types in the dataset
ds$names()
ds$col_types()
ds$col_index('Distance')

# List all the partitions in the dataset
ds$partitions()

# Return number of rows in a given partition
ds$partition_rows('2008-01-03')

# return information on partition range
ds$partitions_range("2008-01-01",'2008-01-30')

# return information on parttitions matching a regex
ds$partitions_regex('2008-01-0?')

# Extract a vector given a partition, split and column index
v <- ds$split('2008-01-03',1,19)

# Or equivalently use column name
v <- ds$splitn('2008-01-03',1,"AirTime")

# Or even simpler use [ where partition and split are combined with :
v <- ds["2008-01-03:1","AirTime"]

# To exact all the columns in a dataframe use as_data_frame_split
df <- as_data_frame_split(ds,'2008-01-03')
@

\subsection{Iterators}

Iterators allow you to iterate over all the partions and splits.

<<>>=
it <- sdf_iterator(ds)
c <- nextElem(it)
c

# Iterate over all partitions and split and do a sum
s <- foreach(i=sdf_iterator(ds),.combine=sum) %do% ds$split(i$pkey,i$split,19)
s
@


\subsection{Dplyr Style Pipeline}

<<>>=
# Create view / pipeline from a dataset
v <- sview(ds)

# Select partions
v <- sv_partitions(v,c("2008-01-03"))

# Select subset of columns
v <- sv_subset(v,c("Distance","AirTime","TaxiIn"))

# Create a row filter
l <- 5
v <- sv_filter(v,Distance > 2000 & TaxiIn < l)

# Execute pipeline
ds2 <- sv_execute(v)
ds2
@

Or even simpler:

<<>>=
ds2 <- sview(ds) %>% 
       sv_partitions(c("2008-01-03")) %>% 
       sv_subset(c('Distance','AirTime','TaxiIn')) %>% 
       sv_filter(Distance > 2000 & TaxiIn < l) %>% 
       sv_execute()
ds2
@


\begin{appendices}

\section{Scythica Dataset format}

\subsection{General Dataset Directory Layout}

Scythica datasets are store in a directory structure as follows:

\begin{verbatim}
dataset.sds/
  data/
      /partition1/
                 /db.mp -- Meta data for partition
                 /column1-00000000.dat  -- column 1 split 1
                 /column1-00000001.dat  -- column 1 split 2
                 /column2-00000000.dat
                ...
      /partition2/
                 /db.mp
                 /column1-00000000.dat
                ..
  factors/
         /column1  -- Map of factor index to value
  schema.cfg -- schema for dataset
\end{verbatim}

\subsection{Partition Meta Data}

Meta data for the partition is stored in a message pack file. Key attributes are:

\begin{itemize}
  \item nrow - Number of rows in the partition
\end{itemize}

\subsection{Data Files}

Data is currently stored in the binary format (currently only tested on x86/64 and arm) in a method compatible with how R internally stores it's raw vectors of data. Data starts offset by 128 bytes to allow for mapping of R's header and R's 3.1 custom allocators.


\section{Low Level Filter Methods}

\subsection{Data Vectors}
Filter operations allow you to select only some rows from a dataset.

<<>>=

m   <- Module("rscythica", PACKAGE="RScythica")
# Create an Integer Vector
bm <- m$SIntVector
bm.v <- new(bm)

v <- ds$split('2008-01-03',1,19)

# Create Filter BitVector
ob <- sindex(length(v))

# Apply == 515
y <- bm.v$op.eq(v,ob,515)
y

# Apply > 1000 & < 1500
a <- bm.v$op.gt(v,ob,1000)
ob2 <- sindex(length(v))
b <- bm.v$op.lt(v,ob2,1500)
c <- sindex(length(v))
bm <- m$BitVector
bv <- new(bm,a)
ov <- bv$op.and(c, b)
res <-  bm.v$collapse(v,ov)
res
@

\subsection{Bitmap Indexes}

<<>>=
# Number of True 
bm <- m$BitVector
bv <- new(bm,y)
bv$popcount()


# Filter row using BitVector
out <- bm.v$collapse(v,y)
length(out)
out

@

\end{appendices}

\end{document}